[project]
name = "capstone-long-context"
version = "0.1.0"
description = "Mistral Small 3.2 기반 64k 롱 컨텍스트 문서 처리 시스템"
authors = [{ name = "AI Team", email = "dev@enterprise.com" }]
requires-python = ">=3.10"

dependencies = [
    "torch>=2.1.0",
    "transformers>=4.38.0",
    "accelerate>=0.27.0",
    "bitsandbytes>=0.42.0",
    "wandb>=0.16.0",
    "weave>=0.50.0",
    "python-dotenv>=1.0.0",
    "sentencepiece>=0.1.99",
    "tqdm>=4.66.0",
    "requests>=2.31.0",
    "numpy<2",
    "pandas>=2.0.0",
    "ipykernel>=7.2.0",
    "matplotlib>=3.10.8",
    "seaborn>=0.13.2",
    "pymupdf>=1.26.7",
    "sentence-transformers>=5.2.2",
    "faiss-gpu>=1.7.2",
    "docling>=2.73.0",
    "pypdf2>=3.0.1",
]

[dependency-groups]
dev = [
    "pytest>=8.0.0",
    "black>=24.0.0",
    "isort>=5.13.0",
]

[tool.uv]
package = false

[tool.uv.sources]
flash-attn = { url = "https://github.com/Dao-AILab/flash-attention/releases/download/v2.5.8/flash_attn-2.5.8+cu122torch2.1cxx11abiFalse-cp310-cp310-linux_x86_64.whl" }

[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"